{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHBLJG2exDL8",
        "outputId": "f0f51082-49bd-43d8-a62d-35825afff5bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AG News Text Classification with Multiple ML Models\n",
            "=================================================\n",
            "1. Load data from local CSV files\n",
            "2. Create sample dataset for testing (using 20 Newsgroups)\n",
            "Enter your choice (1/2): 1\n",
            "Enter path to AG News training CSV file (or enter 'single' if you have only one file): /content/train.csv\n",
            "Enter path to AG News test CSV file: /content/test.csv\n",
            "Available columns in your training file: ['Class Index', 'Title', 'Description']\n",
            "Enter the name of the text column: Description\n",
            "Enter the name of the label/class column: Class Index\n",
            "Training data size: 120000\n",
            "Test data size: 7600\n",
            "Extracting TF-IDF features...\n",
            "Training features shape: (120000, 20000)\n",
            "Test features shape: (7600, 20000)\n",
            "Detected 4 classes: ['World', 'Sports', 'Business', 'Sci/Tech']\n",
            "\n",
            "===== Training Logistic Regression =====\n",
            "Training time: 6.39 seconds\n",
            "Prediction time: 0.00 seconds\n",
            "Accuracy: 0.9089\n",
            "Precision: 0.9087\n",
            "Recall: 0.9089\n",
            "F1-score: 0.9087\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.90      0.91      1900\n",
            "           2       0.95      0.98      0.96      1900\n",
            "           3       0.88      0.87      0.87      1900\n",
            "           4       0.88      0.89      0.89      1900\n",
            "\n",
            "    accuracy                           0.91      7600\n",
            "   macro avg       0.91      0.91      0.91      7600\n",
            "weighted avg       0.91      0.91      0.91      7600\n",
            "\n",
            "\n",
            "===== Training Multinomial Naive Bayes =====\n",
            "Training time: 0.03 seconds\n",
            "Prediction time: 0.00 seconds\n",
            "Accuracy: 0.8936\n",
            "Precision: 0.8932\n",
            "Recall: 0.8936\n",
            "F1-score: 0.8932\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.89      0.90      1900\n",
            "           2       0.94      0.97      0.96      1900\n",
            "           3       0.87      0.84      0.85      1900\n",
            "           4       0.85      0.87      0.86      1900\n",
            "\n",
            "    accuracy                           0.89      7600\n",
            "   macro avg       0.89      0.89      0.89      7600\n",
            "weighted avg       0.89      0.89      0.89      7600\n",
            "\n",
            "\n",
            "===== Training Linear SVM =====\n",
            "Training time: 9.68 seconds\n",
            "Prediction time: 0.00 seconds\n",
            "Accuracy: 0.9130\n",
            "Precision: 0.9128\n",
            "Recall: 0.9130\n",
            "F1-score: 0.9129\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.91      0.92      1900\n",
            "           2       0.95      0.98      0.96      1900\n",
            "           3       0.89      0.88      0.88      1900\n",
            "           4       0.89      0.89      0.89      1900\n",
            "\n",
            "    accuracy                           0.91      7600\n",
            "   macro avg       0.91      0.91      0.91      7600\n",
            "weighted avg       0.91      0.91      0.91      7600\n",
            "\n",
            "\n",
            "===== Training Random Forest =====\n",
            "Training time: 394.37 seconds\n",
            "Prediction time: 0.78 seconds\n",
            "Accuracy: 0.8857\n",
            "Precision: 0.8852\n",
            "Recall: 0.8857\n",
            "F1-score: 0.8850\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.89      0.90      1900\n",
            "           2       0.90      0.97      0.93      1900\n",
            "           3       0.86      0.84      0.85      1900\n",
            "           4       0.87      0.85      0.86      1900\n",
            "\n",
            "    accuracy                           0.89      7600\n",
            "   macro avg       0.89      0.89      0.88      7600\n",
            "weighted avg       0.89      0.89      0.88      7600\n",
            "\n",
            "\n",
            "===== Training K-Nearest Neighbors =====\n",
            "Training time: 0.02 seconds\n",
            "Prediction time: 62.94 seconds\n",
            "Accuracy: 0.4678\n",
            "Precision: 0.7485\n",
            "Recall: 0.4678\n",
            "F1-score: 0.4536\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.83      0.31      0.45      1900\n",
            "           2       0.33      0.99      0.50      1900\n",
            "           3       0.92      0.30      0.46      1900\n",
            "           4       0.92      0.26      0.41      1900\n",
            "\n",
            "    accuracy                           0.47      7600\n",
            "   macro avg       0.75      0.47      0.45      7600\n",
            "weighted avg       0.75      0.47      0.45      7600\n",
            "\n",
            "\n",
            "===== Model Comparison =====\n",
            "                  Model  Accuracy  Precision   Recall  F1-score  Training Time (s)  Prediction Time (s)\n",
            "    Logistic Regression  0.908947   0.908712 0.908947  0.908716           6.389667             0.003549\n",
            "Multinomial Naive Bayes  0.893553   0.893228 0.893553  0.893201           0.030900             0.002061\n",
            "             Linear SVM  0.913026   0.912841 0.913026  0.912858           9.681244             0.003118\n",
            "          Random Forest  0.885658   0.885176 0.885658  0.884995         394.368847             0.778376\n",
            "    K-Nearest Neighbors  0.467763   0.748465 0.467763  0.453612           0.015233            62.935830\n",
            "\n",
            "Best performing model: Linear SVM\n",
            "F1-score: 0.9129\n",
            "Accuracy: 0.9130\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Function to load the AG News dataset from CSV files or create a split from a single file\n",
        "def load_ag_news_from_files():\n",
        "    try:\n",
        "        # Option 1: User provides separate train and test files\n",
        "        train_path = input(\"Enter path to AG News training CSV file (or enter 'single' if you have only one file): \")\n",
        "\n",
        "        if train_path.lower() == 'single':\n",
        "            # Option 2: User provides a single file that we'll split\n",
        "            file_path = input(\"Enter path to your single AG News CSV file: \")\n",
        "            df = pd.read_csv(file_path)\n",
        "\n",
        "            # Confirm column names\n",
        "            print(\"Available columns in your file:\", df.columns.tolist())\n",
        "            text_col = input(\"Enter the name of the text column: \")\n",
        "            label_col = input(\"Enter the name of the label/class column: \")\n",
        "\n",
        "            # Create train/test split\n",
        "            train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df[label_col])\n",
        "\n",
        "            # Rename columns for consistency\n",
        "            train_df = train_df.rename(columns={text_col: 'text', label_col: 'class'})\n",
        "            test_df = test_df.rename(columns={text_col: 'text', label_col: 'class'})\n",
        "\n",
        "        else:\n",
        "            # Load separate train and test files\n",
        "            test_path = input(\"Enter path to AG News test CSV file: \")\n",
        "\n",
        "            train_df = pd.read_csv(train_path)\n",
        "            test_df = pd.read_csv(test_path)\n",
        "\n",
        "            # Confirm column names\n",
        "            print(\"Available columns in your training file:\", train_df.columns.tolist())\n",
        "            text_col = input(\"Enter the name of the text column: \")\n",
        "            label_col = input(\"Enter the name of the label/class column: \")\n",
        "\n",
        "            # Rename columns for consistency\n",
        "            train_df = train_df.rename(columns={text_col: 'text', label_col: 'class'})\n",
        "            test_df = test_df.rename(columns={text_col: 'text', label_col: 'class'})\n",
        "\n",
        "        print(f\"Training data size: {len(train_df)}\")\n",
        "        print(f\"Test data size: {len(test_df)}\")\n",
        "\n",
        "        return train_df, test_df\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading dataset: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Alternative option: Create a simulated dataset for testing\n",
        "def create_sample_dataset():\n",
        "    print(\"Creating a small sample dataset for testing...\")\n",
        "\n",
        "    # For testing: Creating a small sample dataset\n",
        "    from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "    # Get subset of 20 newsgroups for 4 categories (similar to AG News)\n",
        "    categories = ['comp.graphics', 'sci.med', 'rec.sport.baseball', 'talk.politics.misc']\n",
        "    newsgroups = fetch_20newsgroups(subset='all', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "    # Create dataframe\n",
        "    df = pd.DataFrame({\n",
        "        'text': newsgroups.data,\n",
        "        'class': newsgroups.target\n",
        "    })\n",
        "\n",
        "    # Split into train and test\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['class'])\n",
        "\n",
        "    print(f\"Created sample dataset from 20 Newsgroups\")\n",
        "    print(f\"Training data size: {len(train_df)}\")\n",
        "    print(f\"Test data size: {len(test_df)}\")\n",
        "    print(f\"This sample uses classes 0-3, representing: {categories}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "# Feature extraction with TF-IDF\n",
        "def extract_features(train_texts, test_texts):\n",
        "    print(\"Extracting TF-IDF features...\")\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=20000,\n",
        "        ngram_range=(1, 2),  # Unigrams and bigrams\n",
        "        stop_words='english',\n",
        "        min_df=5\n",
        "    )\n",
        "\n",
        "    X_train = vectorizer.fit_transform(train_texts)\n",
        "    X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "    print(f\"Training features shape: {X_train.shape}\")\n",
        "    print(f\"Test features shape: {X_test.shape}\")\n",
        "\n",
        "    return X_train, X_test, vectorizer\n",
        "\n",
        "# Function to evaluate models and return metrics\n",
        "def evaluate_model(y_true, y_pred):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1\n",
        "    }\n",
        "\n",
        "# Function to train and evaluate each model\n",
        "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name):\n",
        "    print(f\"\\n===== Training {model_name} =====\")\n",
        "\n",
        "    # Training\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - start_time\n",
        "    print(f\"Training time: {train_time:.2f} seconds\")\n",
        "\n",
        "    # Prediction\n",
        "    start_time = time.time()\n",
        "    y_pred = model.predict(X_test)\n",
        "    predict_time = time.time() - start_time\n",
        "    print(f\"Prediction time: {predict_time:.2f} seconds\")\n",
        "\n",
        "    # Evaluation\n",
        "    metrics = evaluate_model(y_test, y_pred)\n",
        "\n",
        "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
        "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"F1-score: {metrics['f1']:.4f}\")\n",
        "\n",
        "    # Detailed report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return {\n",
        "        'model_name': model_name,\n",
        "        'model': model,\n",
        "        'accuracy': metrics['accuracy'],\n",
        "        'precision': metrics['precision'],\n",
        "        'recall': metrics['recall'],\n",
        "        'f1': metrics['f1'],\n",
        "        'train_time': train_time,\n",
        "        'predict_time': predict_time,\n",
        "        'predictions': y_pred\n",
        "    }\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, model_name, class_names=None):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.title(f'Confusion Matrix - {model_name}')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'confusion_matrix_{model_name.replace(\" \", \"_\").lower()}.png')\n",
        "    plt.close()\n",
        "\n",
        "# Function to compare model performances\n",
        "def compare_models(results):\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
        "    models = [result['model_name'] for result in results]\n",
        "\n",
        "    # Create comparison dataframe\n",
        "    comparison_df = pd.DataFrame({\n",
        "        'Model': models,\n",
        "        'Accuracy': [result['accuracy'] for result in results],\n",
        "        'Precision': [result['precision'] for result in results],\n",
        "        'Recall': [result['recall'] for result in results],\n",
        "        'F1-score': [result['f1'] for result in results],\n",
        "        'Training Time (s)': [result['train_time'] for result in results],\n",
        "        'Prediction Time (s)': [result['predict_time'] for result in results]\n",
        "    })\n",
        "\n",
        "    print(\"\\n===== Model Comparison =====\")\n",
        "    print(comparison_df.to_string(index=False))\n",
        "\n",
        "    # Save comparison to CSV\n",
        "    comparison_df.to_csv('model_comparison.csv', index=False)\n",
        "\n",
        "    # Plotting accuracy, precision, recall, f1\n",
        "    plt.figure(figsize=(12, 8))\n",
        "\n",
        "    bar_width = 0.2\n",
        "    index = np.arange(len(models))\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        values = [result[metric] for result in results]\n",
        "        plt.bar(index + i*bar_width, values, bar_width, label=metric.capitalize())\n",
        "\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.xticks(index + bar_width*1.5, models, rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_performance_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot training and prediction times\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    train_times = [result['train_time'] for result in results]\n",
        "    predict_times = [result['predict_time'] for result in results]\n",
        "\n",
        "    x = np.arange(len(models))\n",
        "    width = 0.35\n",
        "\n",
        "    plt.bar(x - width/2, train_times, width, label='Training Time (s)')\n",
        "    plt.bar(x + width/2, predict_times, width, label='Prediction Time (s)')\n",
        "\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Time (seconds)')\n",
        "    plt.title('Model Training and Prediction Times')\n",
        "    plt.xticks(x, models, rotation=45)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_time_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "    return comparison_df\n",
        "\n",
        "def main():\n",
        "    print(\"AG News Text Classification with Multiple ML Models\")\n",
        "    print(\"=================================================\")\n",
        "    print(\"1. Load data from local CSV files\")\n",
        "    print(\"2. Create sample dataset for testing (using 20 Newsgroups)\")\n",
        "    choice = input(\"Enter your choice (1/2): \")\n",
        "\n",
        "    if choice == \"1\":\n",
        "        # Load AG News dataset from files\n",
        "        train_df, test_df = load_ag_news_from_files()\n",
        "    else:\n",
        "        # Create sample dataset\n",
        "        train_df, test_df = create_sample_dataset()\n",
        "\n",
        "    if train_df is None:\n",
        "        print(\"Could not load or create dataset. Exiting.\")\n",
        "        return\n",
        "\n",
        "    # Extract features\n",
        "    X_train, X_test, vectorizer = extract_features(train_df['text'], test_df['text'])\n",
        "    y_train = train_df['class']\n",
        "    y_test = test_df['class']\n",
        "\n",
        "    # Determine number of classes and create class names\n",
        "    num_classes = len(np.unique(y_train))\n",
        "    if num_classes == 4:  # Assuming AG News 4 classes\n",
        "        class_names = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]\n",
        "    else:\n",
        "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
        "\n",
        "    print(f\"Detected {num_classes} classes: {class_names}\")\n",
        "\n",
        "    # Define all models to train and evaluate\n",
        "    models = [\n",
        "        {\n",
        "            'name': 'Logistic Regression',\n",
        "            'model': LogisticRegression(C=1.0, max_iter=100, solver='liblinear', random_state=42)\n",
        "        },\n",
        "        {\n",
        "            'name': 'Multinomial Naive Bayes',\n",
        "            'model': MultinomialNB(alpha=0.1)\n",
        "        },\n",
        "        {\n",
        "            'name': 'Linear SVM',\n",
        "            'model': LinearSVC(C=1.0, max_iter=1000, dual=False, random_state=42)\n",
        "        },\n",
        "        {\n",
        "            'name': 'Random Forest',\n",
        "            'model': RandomForestClassifier(n_estimators=100, max_depth=None, n_jobs=-1, random_state=42)\n",
        "        },\n",
        "        {\n",
        "            'name': 'K-Nearest Neighbors',\n",
        "            'model': KNeighborsClassifier(n_neighbors=5, weights='distance', n_jobs=-1)\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Train and evaluate all models\n",
        "    results = []\n",
        "    for model_info in models:\n",
        "        result = train_and_evaluate(\n",
        "            model_info['model'],\n",
        "            X_train, y_train,\n",
        "            X_test, y_test,\n",
        "            model_info['name']\n",
        "        )\n",
        "        results.append(result)\n",
        "\n",
        "        # Plot confusion matrix\n",
        "        plot_confusion_matrix(y_test, result['predictions'], model_info['name'], class_names)\n",
        "\n",
        "    # Compare models\n",
        "    comparison_df = compare_models(results)\n",
        "\n",
        "    # Identify best model\n",
        "    best_model = max(results, key=lambda x: x['f1'])\n",
        "    print(f\"\\nBest performing model: {best_model['model_name']}\")\n",
        "    print(f\"F1-score: {best_model['f1']:.4f}\")\n",
        "    print(f\"Accuracy: {best_model['accuracy']:.4f}\")\n",
        "\n",
        "    # Optional: Write summary observations\n",
        "    with open('model_observations.txt', 'w') as f:\n",
        "        f.write(\"# Text Classification Model Comparison on AG News Dataset\\n\\n\")\n",
        "        f.write(\"## Performance Summary\\n\\n\")\n",
        "        f.write(f\"{comparison_df.to_string(index=False)}\\n\")\n",
        "        f.write(\"\\n\\n## Observations\\n\\n\")\n",
        "        f.write(f\"- Best performing model: {best_model['model_name']} with F1-score of {best_model['f1']:.4f}\\n\")\n",
        "\n",
        "        # Add speed observations\n",
        "        fastest_training = min(results, key=lambda x: x['train_time'])\n",
        "        fastest_prediction = min(results, key=lambda x: x['predict_time'])\n",
        "        f.write(f\"- Fastest training model: {fastest_training['model_name']} ({fastest_training['train_time']:.2f}s)\\n\")\n",
        "        f.write(f\"- Fastest prediction model: {fastest_prediction['model_name']} ({fastest_prediction['predict_time']:.2f}s)\\n\")\n",
        "\n",
        "        # Model strengths and trade-offs\n",
        "        f.write(\"\\n## Model Strengths and Trade-offs\\n\\n\")\n",
        "        f.write(\"### Logistic Regression\\n\")\n",
        "        f.write(\"- Good balance between accuracy and training speed\\n\")\n",
        "        f.write(\"- Works well with high-dimensional sparse data like TF-IDF\\n\")\n",
        "\n",
        "        f.write(\"\\n### Multinomial Naive Bayes\\n\")\n",
        "        f.write(\"- Very fast training and prediction\\n\")\n",
        "        f.write(\"- Good performance for text classification with count-based features\\n\")\n",
        "\n",
        "        f.write(\"\\n### Linear SVM\\n\")\n",
        "        f.write(\"- Usually achieves high accuracy on text classification tasks\\n\")\n",
        "        f.write(\"- Works well with high-dimensional data but can be slow to train on large datasets\\n\")\n",
        "\n",
        "        f.write(\"\\n### Random Forest\\n\")\n",
        "        f.write(\"- Robust to overfitting\\n\")\n",
        "        f.write(\"- Can capture non-linear relationships but may not be ideal for high-dimensional sparse data\\n\")\n",
        "\n",
        "        f.write(\"\\n### K-Nearest Neighbors\\n\")\n",
        "        f.write(\"- Simple implementation but often slower for predictions\\n\")\n",
        "        f.write(\"- Performance heavily dependent on feature scaling and neighborhood size\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}